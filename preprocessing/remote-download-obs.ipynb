{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42bc784-eaa3-4840-848d-f30fdeb2aeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef046ee8-b64c-4826-bdc7-b4fdfbd62ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dask.diagnostics import ProgressBar\n",
    "from pathlib import Path\n",
    "import cdsapi\n",
    "import libs.utils\n",
    "import libs.vars\n",
    "import urllib\n",
    "import xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5676f9f-9f2e-4490-bd8e-ccbc3b75e52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve UKESM grid to re-grid to\n",
    "base_path = '_data/cmip6'\n",
    "ukesm_file = f'/UKESM1-0-LL/siconc/siconc_SImon_UKESM1-0-LL_ssp585_r2i1p1f2_gn_201501-204912.nc'\n",
    "ukesm_path = f'{base_path}{ukesm_file}'\n",
    "not Path(ukesm_path).exists() and libs.utils.download_variable(**{\n",
    "    'experiment_id': 'ssp585',\n",
    "    'frequency': 'mon',\n",
    "    'variable_id': 'siconc',\n",
    "    'save_to_local': True,\n",
    "    'source_id': 'UKESM1-0-LL',\n",
    "    'table_id': 'SImon',\n",
    "    'variant_label': 'r2i1p1f2'\n",
    "})\n",
    "ukesm_grid = xarray.open_mfdataset(\n",
    "    paths=ukesm_path, \n",
    "    combine='by_coords',\n",
    "    use_cftime=True\n",
    ")\n",
    "\n",
    "regrid_s2d = {\n",
    "    'grid': ukesm_grid,\n",
    "    'method': 'nearest_s2d',\n",
    "    'copy_dims': ['i', 'j', 'longitude', 'latitude', 'vertices']\n",
    "}\n",
    "regrid_bil_s2d = {\n",
    "    'grid': ukesm_grid,\n",
    "    'method': 'bilinear',\n",
    "    'extrap_method': 'nearest_s2d',\n",
    "    'copy_dims': ['i', 'j', 'longitude', 'latitude', 'vertices']\n",
    "}\n",
    "\n",
    "obs_base_path = '_data/_cache/_obs'\n",
    "time_slice = slice('1980-01-01', '2021-01-01')\n",
    "variables_obs = [\n",
    "    {\n",
    "        'regrid_kwargs': regrid_s2d,\n",
    "        'url': 'https://www.metoffice.gov.uk/hadobs/hadisst/data/HadISST_ice.nc', # '.gz'\n",
    "        'variable_id': 'sic',\n",
    "    },\n",
    "    {\n",
    "        'regrid_kwargs': regrid_s2d,\n",
    "        'url': 'https://www.metoffice.gov.uk/hadobs/hadisst2/data/HadISST.2.2.0.0_sea_ice_concentration.nc',\n",
    "        'variable_id': 'sic',\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493c4f45-d453-4cf2-bd04-77fb6effbb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = cdsapi.Client()\n",
    "\n",
    "era5_variables = [\n",
    "    { 'name': '2m_temperature', 'regrid_kwargs': regrid_bil_s2d, 'variable_id': 't2m' }, \n",
    "    { 'name': 'evaporation', 'regrid_kwargs': regrid_bil_s2d, 'variable_id': 'e' }, \n",
    "    { 'name': 'sea_surface_temperature', 'regrid_kwargs': regrid_s2d, 'variable_id': 'sst' }, \n",
    "    { 'name': 'snowfall', 'regrid_kwargs': regrid_s2d, 'variable_id': 'sf' }, \n",
    "    { 'name': 'total_precipitation', 'regrid_kwargs': regrid_s2d, 'variable_id': 'tp' }\n",
    "]\n",
    "\n",
    "for v in era5_variables:\n",
    "    v_name = v['name']\n",
    "    filename = f'era5_{v_name}_1980-2020.nc'\n",
    "    dest = f'{obs_base_path}/{filename}'\n",
    "\n",
    "    not Path(dest).exists() and c.retrieve(\n",
    "        'reanalysis-era5-single-levels-monthly-means',\n",
    "        {\n",
    "            'format': 'netcdf',\n",
    "            'product_type': 'monthly_averaged_reanalysis',\n",
    "            'variable': v_name,\n",
    "            'year': [\n",
    "                '1980', '1981', '1982',\n",
    "                '1983', '1984', '1985',\n",
    "                '1986', '1987', '1988',\n",
    "                '1989', '1990', '1991',\n",
    "                '1992', '1993', '1994',\n",
    "                '1995', '1996', '1997',\n",
    "                '1998', '1999', '2000',\n",
    "                '2001', '2002', '2003',\n",
    "                '2004', '2005', '2006',\n",
    "                '2007', '2008', '2009',\n",
    "                '2010', '2011', '2012',\n",
    "                '2013', '2014', '2015',\n",
    "                '2016', '2017', '2018',\n",
    "                '2019', '2020',\n",
    "            ],\n",
    "            'month': [\n",
    "                '01', '02', '03',\n",
    "                '04', '05', '06',\n",
    "                '07', '08', '09',\n",
    "                '10', '11', '12',\n",
    "            ],\n",
    "            'time': '00:00',\n",
    "        },\n",
    "        dest\n",
    "    )\n",
    "    \n",
    "    variables_obs.append({\n",
    "        'regrid_kwargs':  v['regrid_kwargs'],\n",
    "        'url': filename,\n",
    "        'variable_id': v['variable_id'],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420cbfd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_url(url):\n",
    "    filename = urllib.parse.urlparse(url).path.split('/')[-1]    \n",
    "    local_filename = Path(obs_base_path, filename)\n",
    "    local_filename.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    if local_filename.exists():\n",
    "        print(f'   -> Already exists, skipping: {local_filename}')\n",
    "        return local_filename\n",
    "    \n",
    "    try:\n",
    "        print(f'   -> Downloading:')\n",
    "        print(f'   -> {url}')\n",
    "        print(f'   -> {local_filename}')\n",
    "        urllib.request.urlretrieve(url, local_filename)\n",
    "    except Exception as e:\n",
    "        print('An error occurred during initial query', e, sep='\\n')\n",
    "        return None\n",
    "\n",
    "    return local_filename\n",
    "\n",
    "\n",
    "files = []\n",
    "plot_variable = 'sic'\n",
    "\n",
    "for v in variables_obs:\n",
    "    local_file = download_url(v['url'])\n",
    "    if local_file == None:\n",
    "        continue\n",
    "    \n",
    "    local_file_processed = Path(str(local_file).replace('.nc', '_processed.nc'))\n",
    "    if local_file_processed.exists():\n",
    "        # Cleanup & return\n",
    "        print('   -> Processed file already exists, skipping write')\n",
    "        plot_variable == v['variable_id'] and files.append(local_file_processed)\n",
    "        continue\n",
    "    \n",
    "    arr = xarray.open_mfdataset(\n",
    "        paths=local_file, \n",
    "        autoclose=True,\n",
    "        use_cftime=True\n",
    "    )\n",
    "    arr = arr.sel(time=time_slice)\n",
    "    arr = libs.utils.regrid(arr, **v['regrid_kwargs'])\n",
    "    \n",
    "    # Write to file\n",
    "    print(f'   -> Writing to {local_file_processed}')\n",
    "    write = arr.to_netcdf(\n",
    "        local_file_processed,\n",
    "        compute=False,\n",
    "        engine='netcdf4',\n",
    "        unlimited_dims=['time']\n",
    "    )\n",
    "    with ProgressBar():\n",
    "        write.compute()\n",
    "\n",
    "    arr.close()\n",
    "    \n",
    "    # Finally, compress as to_netcdf() seems to produce large file sizes\n",
    "    local_file_processed, diff = libs.utils.compress_nc_file(local_file_processed, local_file_processed)\n",
    "    print(f'   -> Compressed (Savings: {diff})')\n",
    "\n",
    "    plot_variable == v['variable_id'] and files.append(local_file_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3dd17f-0823-441a-8741-d96ae3777ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import libs.plot\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "file_data = []\n",
    "for file in files:\n",
    "    item_data = xarray.open_mfdataset(\n",
    "        paths=file, \n",
    "        combine='by_coords',\n",
    "        use_cftime=True\n",
    "    )\n",
    "    file_data.append({\n",
    "        'data': item_data[plot_variable][6, :, :],\n",
    "        'label': plot_variable\n",
    "    })\n",
    "\n",
    "libs.plot.nstereo(\n",
    "    file_data,\n",
    "    title=f'Ensemble {plot_variable}, (1) HadISST1, (2) HadISST2.2',\n",
    "    colorbar_label=plot_variable,\n",
    "    colormesh_kwargs={\n",
    "        'cmap': 'RdBu_r',\n",
    "        'extend': 'both',\n",
    "        'levels': 21,\n",
    "        'vmin': 0,\n",
    "        'vmax': 1,\n",
    "        'x': 'longitude', \n",
    "        'y': 'latitude'\n",
    "    },\n",
    "    shape=(1, len(file_data))\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bcddd4-c44b-4b41-b96c-8d57f44732e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate",
   "language": "python",
   "name": "climate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
